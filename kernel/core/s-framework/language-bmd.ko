/*
 * Language BMD Processing Kernel Module
 * 
 * Implements matrix associative memories for language processing
 * Based on neurocomputational models of modular language networks
 * Integrates with S-distance optimization for enhanced linguistic BMD transfer
 * 
 * Inspired by: "Neurocomputational models of language organization"
 * Cabana et al. research on matrix associative memories and discourse analysis
 * 
 * Copyright (C) 2024 Buhera S-Enhanced VPOS Project
 * Licensed under GPL v3
 */

#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/init.h>
#include <linux/proc_fs.h>
#include <linux/seq_file.h>
#include <linux/uaccess.h>
#include <linux/spinlock.h>
#include <linux/ktime.h>
#include <linux/atomic.h>
#include <linux/workqueue.h>
#include <linux/timer.h>
#include <linux/sched.h>
#include <linux/mm.h>
#include <linux/slab.h>
#include <linux/random.h>
#include <linux/string.h>

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Buhera S-Enhanced VPOS Team");
MODULE_DESCRIPTION("Language BMD Processing with matrix associative memories");
MODULE_VERSION("1.0.0");

// Import S-distance measurement interface
struct s_distance_measurement {
    u64 s_knowledge;
    u64 s_time;
    u64 s_entropy;
    u64 global_s;
    ktime_t timestamp;
    u32 process_id;
    u8 observer_level;
};

// External functions from other S-framework modules
extern int s_distance_get_current(struct s_distance_measurement *measurement);

// Language BMD matrix structure
struct language_matrix {
    u32 matrix_id;
    u32 dimensions;          // Matrix dimensions (typically 512-2048)
    s32 *weight_matrix;      // Weight matrix for associative memory
    u32 *context_vector;     // Current context vector
    u32 *goal_vector;        // Goal-oriented target vector
    u64 activation_count;    // Number of activations
    u64 successful_recalls;  // Successful memory recalls
    u32 context_strength;    // Context dependency strength (0-1000)
    u32 semantic_coherence;  // Semantic coherence measure (0-1000)
    ktime_t last_activation; // Last activation timestamp
    bool active;
};

// Language BMD module structure
struct language_bmd_module {
    u32 module_id;
    char module_name[64];    // Module name (e.g., "lexical", "syntactic", "semantic")
    struct language_matrix *core_matrix;
    struct language_matrix *context_matrices[8]; // Multiple context-dependent matrices
    u32 active_context_count;
    u64 total_processings;
    u64 successful_transfers;
    u64 discourse_coherence; // Overall discourse coherence (0-10000)
    spinlock_t module_lock;
    bool module_active;
};

// Discourse trajectory point for analysis
struct discourse_point {
    u32 semantic_vector[256]; // Semantic representation vector
    u32 coherence_score;      // Local coherence score
    u32 topic_stability;      // Topic stability measure
    u32 connectivity_degree;  // Connectivity to other points
    ktime_t timestamp;        // When this point was generated
};

// Discourse trajectory for tracking language production
struct discourse_trajectory {
    struct discourse_point points[1024]; // Trajectory points
    u32 trajectory_length;
    u32 overall_coherence;    // Overall trajectory coherence
    u32 disorder_measure;     // Discourse disorder quantification
    u32 semantic_connectivity; // Global semantic connectivity
    bool hyperconnection_detected; // Disconnection-hyperconnection paradox
    spinlock_t trajectory_lock;
};

// Language BMD processing context
struct language_bmd_context {
    struct language_bmd_module modules[16]; // Multiple language modules
    u32 active_module_count;
    struct discourse_trajectory current_trajectory;
    struct discourse_trajectory target_trajectory;
    u64 total_bmd_transfers;
    u64 successful_bmd_transfers;
    u64 language_s_optimizations;
    atomic64_t processing_cycles;
    spinlock_t context_lock;
    struct workqueue_struct *language_wq;
    struct delayed_work language_work;
    bool active;
    bool discourse_analysis_enabled;
};

// Global language BMD context
static struct language_bmd_context lang_bmd_ctx;

// Language processing constants
#define LANG_PROCESSING_INTERVAL    1000  // microseconds
#define MAX_LANGUAGE_MODULES        16
#define MAX_CONTEXT_MATRICES        8
#define MATRIX_DEFAULT_DIMENSIONS   512
#define DISCOURSE_TRAJECTORY_SIZE   1024
#define SEMANTIC_VECTOR_SIZE        256
#define COHERENCE_THRESHOLD         700    // Minimum coherence for successful transfer
#define HYPERCONNECTION_THRESHOLD   800    // Threshold for hyperconnection detection

/*
 * Matrix associative memory operations
 */

static int allocate_language_matrix(struct language_matrix *matrix, u32 dimensions)
{
    if (!matrix || dimensions == 0 || dimensions > 4096)
        return -EINVAL;
    
    matrix->dimensions = dimensions;
    matrix->weight_matrix = kzalloc(dimensions * dimensions * sizeof(s32), GFP_KERNEL);
    matrix->context_vector = kzalloc(dimensions * sizeof(u32), GFP_KERNEL);
    matrix->goal_vector = kzalloc(dimensions * sizeof(u32), GFP_KERNEL);
    
    if (!matrix->weight_matrix || !matrix->context_vector || !matrix->goal_vector) {
        kfree(matrix->weight_matrix);
        kfree(matrix->context_vector);
        kfree(matrix->goal_vector);
        return -ENOMEM;
    }
    
    matrix->activation_count = 0;
    matrix->successful_recalls = 0;
    matrix->context_strength = 500;  // Medium context dependency
    matrix->semantic_coherence = 1000; // Start with high coherence
    matrix->last_activation = ktime_get();
    matrix->active = true;
    
    return 0;
}

static void free_language_matrix(struct language_matrix *matrix)
{
    if (!matrix)
        return;
    
    kfree(matrix->weight_matrix);
    kfree(matrix->context_vector);
    kfree(matrix->goal_vector);
    
    matrix->weight_matrix = NULL;
    matrix->context_vector = NULL;
    matrix->goal_vector = NULL;
    matrix->active = false;
}

static u32 compute_matrix_activation(struct language_matrix *matrix, 
                                    const u32 *input_vector,
                                    u32 *output_vector)
{
    u32 i, j;
    s64 activation_sum;
    u32 total_activation = 0;
    
    if (!matrix || !matrix->active || !input_vector || !output_vector)
        return 0;
    
    // Matrix-vector multiplication for associative recall
    for (i = 0; i < matrix->dimensions; i++) {
        activation_sum = 0;
        
        for (j = 0; j < matrix->dimensions; j++) {
            activation_sum += (s64)matrix->weight_matrix[i * matrix->dimensions + j] * 
                             input_vector[j];
        }
        
        // Apply context-dependent modulation
        activation_sum = (activation_sum * matrix->context_strength) / 1000;
        
        // Nonlinear activation function (sigmoid-like)
        if (activation_sum > 0) {
            output_vector[i] = min((u32)(activation_sum / 1000), 1000U);
        } else {
            output_vector[i] = 0;
        }
        
        total_activation += output_vector[i];
    }
    
    matrix->activation_count++;
    matrix->last_activation = ktime_get();
    
    return total_activation;
}

static void update_matrix_weights(struct language_matrix *matrix,
                                 const u32 *input_vector,
                                 const u32 *target_vector,
                                 u32 learning_rate)
{
    u32 i, j;
    s32 weight_delta;
    
    if (!matrix || !matrix->active || !input_vector || !target_vector)
        return;
    
    // Hebbian learning with context dependency
    for (i = 0; i < matrix->dimensions; i++) {
        for (j = 0; j < matrix->dimensions; j++) {
            // Calculate weight change based on input-target correlation
            weight_delta = ((s32)input_vector[i] * (s32)target_vector[j] * learning_rate) / 1000;
            
            // Apply context-dependent modulation
            weight_delta = (weight_delta * matrix->context_strength) / 1000;
            
            // Update weight with bounded increment
            matrix->weight_matrix[i * matrix->dimensions + j] += weight_delta;
            
            // Bound weights to prevent overflow
            if (matrix->weight_matrix[i * matrix->dimensions + j] > 10000) {
                matrix->weight_matrix[i * matrix->dimensions + j] = 10000;
            } else if (matrix->weight_matrix[i * matrix->dimensions + j] < -10000) {
                matrix->weight_matrix[i * matrix->dimensions + j] = -10000;
            }
        }
    }
}

/*
 * Language BMD module operations
 */

static int initialize_language_module(struct language_bmd_module *module,
                                     u32 module_id,
                                     const char *name)
{
    int ret, i;
    
    if (!module || !name)
        return -EINVAL;
    
    module->module_id = module_id;
    strncpy(module->module_name, name, sizeof(module->module_name) - 1);
    module->module_name[sizeof(module->module_name) - 1] = '\0';
    
    // Allocate core matrix
    module->core_matrix = kzalloc(sizeof(struct language_matrix), GFP_KERNEL);
    if (!module->core_matrix)
        return -ENOMEM;
    
    ret = allocate_language_matrix(module->core_matrix, MATRIX_DEFAULT_DIMENSIONS);
    if (ret) {
        kfree(module->core_matrix);
        return ret;
    }
    
    module->core_matrix->matrix_id = 0;
    
    // Initialize context matrices
    module->active_context_count = 0;
    for (i = 0; i < MAX_CONTEXT_MATRICES; i++) {
        module->context_matrices[i] = NULL;
    }
    
    module->total_processings = 0;
    module->successful_transfers = 0;
    module->discourse_coherence = 1000; // Start with high coherence
    spin_lock_init(&module->module_lock);
    module->module_active = true;
    
    return 0;
}

static void cleanup_language_module(struct language_bmd_module *module)
{
    int i;
    
    if (!module)
        return;
    
    if (module->core_matrix) {
        free_language_matrix(module->core_matrix);
        kfree(module->core_matrix);
        module->core_matrix = NULL;
    }
    
    for (i = 0; i < MAX_CONTEXT_MATRICES; i++) {
        if (module->context_matrices[i]) {
            free_language_matrix(module->context_matrices[i]);
            kfree(module->context_matrices[i]);
            module->context_matrices[i] = NULL;
        }
    }
    
    module->module_active = false;
}

static u32 process_language_bmd(struct language_bmd_module *module,
                               const u32 *input_semantic_vector,
                               u32 *output_semantic_vector,
                               u32 context_id)
{
    struct language_matrix *active_matrix;
    u32 activation_strength;
    u32 coherence_score = 0;
    unsigned long flags;
    
    if (!module || !module->module_active || !input_semantic_vector || !output_semantic_vector)
        return 0;
    
    spin_lock_irqsave(&module->module_lock, flags);
    
    // Select appropriate matrix (core or context-specific)
    if (context_id < module->active_context_count && 
        module->context_matrices[context_id] && 
        module->context_matrices[context_id]->active) {
        active_matrix = module->context_matrices[context_id];
    } else {
        active_matrix = module->core_matrix;
    }
    
    // Perform matrix associative recall
    activation_strength = compute_matrix_activation(active_matrix, 
                                                   input_semantic_vector,
                                                   output_semantic_vector);
    
    // Calculate semantic coherence
    if (activation_strength > 0) {
        coherence_score = min(activation_strength / 10, 1000U);
        active_matrix->successful_recalls++;
        module->successful_transfers++;
    }
    
    module->total_processings++;
    
    // Update discourse coherence based on processing success
    if (coherence_score > COHERENCE_THRESHOLD) {
        module->discourse_coherence = min(module->discourse_coherence + 10, 10000ULL);
    } else {
        module->discourse_coherence = max(module->discourse_coherence - 5, 0ULL);
    }
    
    spin_unlock_irqrestore(&module->module_lock, flags);
    
    return coherence_score;
}

/*
 * Discourse trajectory analysis
 */

static void add_discourse_point(struct discourse_trajectory *trajectory,
                               const u32 *semantic_vector,
                               u32 coherence_score)
{
    struct discourse_point *point;
    u32 index;
    unsigned long flags;
    int i;
    
    if (!trajectory || !semantic_vector)
        return;
    
    spin_lock_irqsave(&trajectory->trajectory_lock, flags);
    
    index = trajectory->trajectory_length % DISCOURSE_TRAJECTORY_SIZE;
    point = &trajectory->points[index];
    
    // Copy semantic vector
    for (i = 0; i < SEMANTIC_VECTOR_SIZE; i++) {
        point->semantic_vector[i] = semantic_vector[i];
    }
    
    point->coherence_score = coherence_score;
    point->timestamp = ktime_get();
    
    // Calculate topic stability (similarity with previous point)
    if (trajectory->trajectory_length > 0) {
        u32 prev_index = (index - 1 + DISCOURSE_TRAJECTORY_SIZE) % DISCOURSE_TRAJECTORY_SIZE;
        struct discourse_point *prev_point = &trajectory->points[prev_index];
        u32 similarity = 0;
        
        for (i = 0; i < SEMANTIC_VECTOR_SIZE; i++) {
            u32 diff = (point->semantic_vector[i] > prev_point->semantic_vector[i]) ?
                      (point->semantic_vector[i] - prev_point->semantic_vector[i]) :
                      (prev_point->semantic_vector[i] - point->semantic_vector[i]);
            similarity += (1000 - min(diff, 1000U));
        }
        
        point->topic_stability = similarity / SEMANTIC_VECTOR_SIZE;
    } else {
        point->topic_stability = 1000; // First point has maximum stability
    }
    
    // Calculate connectivity degree (connections to other recent points)
    point->connectivity_degree = 0;
    for (i = 1; i <= min(trajectory->trajectory_length, 10U); i++) {
        u32 other_index = (index - i + DISCOURSE_TRAJECTORY_SIZE) % DISCOURSE_TRAJECTORY_SIZE;
        struct discourse_point *other_point = &trajectory->points[other_index];
        
        u32 connection_strength = 0;
        int j;
        for (j = 0; j < SEMANTIC_VECTOR_SIZE; j++) {
            if (point->semantic_vector[j] > 0 && other_point->semantic_vector[j] > 0) {
                connection_strength += min(point->semantic_vector[j], other_point->semantic_vector[j]);
            }
        }
        
        if (connection_strength > 5000) { // Threshold for significant connection
            point->connectivity_degree++;
        }
    }
    
    trajectory->trajectory_length++;
    
    // Update overall trajectory metrics
    u32 total_coherence = 0;
    u32 total_connectivity = 0;
    u32 points_to_analyze = min(trajectory->trajectory_length, 100U);
    
    for (i = 0; i < points_to_analyze; i++) {
        u32 point_index = (index - i + DISCOURSE_TRAJECTORY_SIZE) % DISCOURSE_TRAJECTORY_SIZE;
        total_coherence += trajectory->points[point_index].coherence_score;
        total_connectivity += trajectory->points[point_index].connectivity_degree;
    }
    
    trajectory->overall_coherence = total_coherence / points_to_analyze;
    trajectory->semantic_connectivity = total_connectivity / points_to_analyze;
    
    // Calculate disorder measure (inverse of coherence with connectivity factor)
    trajectory->disorder_measure = 1000 - trajectory->overall_coherence;
    
    // Detect hyperconnection paradox
    if (trajectory->overall_coherence < 300 && // Low local coherence
        trajectory->semantic_connectivity > HYPERCONNECTION_THRESHOLD) { // High connectivity
        trajectory->hyperconnection_detected = true;
    } else {
        trajectory->hyperconnection_detected = false;
    }
    
    spin_unlock_irqrestore(&trajectory->trajectory_lock, flags);
}

/*
 * Language BMD processing worker function
 */
static void language_bmd_worker(struct work_struct *work)
{
    struct language_bmd_context *ctx = container_of(to_delayed_work(work),
                                                   struct language_bmd_context,
                                                   language_work);
    struct s_distance_measurement s_measurement;
    u32 input_semantic_vector[SEMANTIC_VECTOR_SIZE];
    u32 output_semantic_vector[SEMANTIC_VECTOR_SIZE];
    u32 i, coherence_score;
    unsigned long flags;
    bool processing_occurred = false;
    
    atomic64_inc(&ctx->processing_cycles);
    
    // Get current S-distance for language optimization
    if (s_distance_get_current(&s_measurement) == 0) {
        // Generate input semantic vector based on S-distance state
        for (i = 0; i < SEMANTIC_VECTOR_SIZE; i++) {
            input_semantic_vector[i] = (u32)((s_measurement.s_knowledge + 
                                             s_measurement.s_time + 
                                             s_measurement.s_entropy + i) % 1000);
        }
        
        spin_lock_irqsave(&ctx->context_lock, flags);
        
        // Process through active language modules
        for (i = 0; i < ctx->active_module_count; i++) {
            if (ctx->modules[i].module_active) {
                coherence_score = process_language_bmd(&ctx->modules[i],
                                                      input_semantic_vector,
                                                      output_semantic_vector,
                                                      0); // Use core matrix
                
                if (coherence_score > 0) {
                    processing_occurred = true;
                    ctx->total_bmd_transfers++;
                    
                    if (coherence_score > COHERENCE_THRESHOLD) {
                        ctx->successful_bmd_transfers++;
                        ctx->language_s_optimizations++;
                    }
                    
                    // Add to discourse trajectory if analysis is enabled
                    if (ctx->discourse_analysis_enabled) {
                        add_discourse_point(&ctx->current_trajectory,
                                          output_semantic_vector,
                                          coherence_score);
                    }
                }
            }
        }
        
        spin_unlock_irqrestore(&ctx->context_lock, flags);
    }
    
    // Schedule next processing cycle
    if (ctx->active) {
        queue_delayed_work(ctx->language_wq, &ctx->language_work,
                          usecs_to_jiffies(LANG_PROCESSING_INTERVAL));
    }
}

/*
 * Proc filesystem interface
 */
static int language_bmd_proc_show(struct seq_file *m, void *v)
{
    struct language_bmd_context ctx_copy;
    unsigned long flags;
    u32 i;
    u64 processing_cycles;
    
    spin_lock_irqsave(&lang_bmd_ctx.context_lock, flags);
    ctx_copy = lang_bmd_ctx;
    spin_unlock_irqrestore(&lang_bmd_ctx.context_lock, flags);
    
    processing_cycles = atomic64_read(&lang_bmd_ctx.processing_cycles);
    
    seq_printf(m, "Language BMD Processing System Status\n");
    seq_printf(m, "====================================\n\n");
    
    seq_printf(m, "Active Language Modules (%u/%u):\n", ctx_copy.active_module_count, MAX_LANGUAGE_MODULES);
    for (i = 0; i < ctx_copy.active_module_count; i++) {
        struct language_bmd_module *module = &ctx_copy.modules[i];
        u32 success_rate = 0;
        
        if (module->total_processings > 0) {
            success_rate = (u32)((module->successful_transfers * 100) / module->total_processings);
        }
        
        seq_printf(m, "  Module %u (%s):\n", module->module_id, module->module_name);
        seq_printf(m, "    Total Processings: %llu\n", module->total_processings);
        seq_printf(m, "    Successful Transfers: %llu\n", module->successful_transfers);
        seq_printf(m, "    Success Rate: %u%%\n", success_rate);
        seq_printf(m, "    Discourse Coherence: %llu/10000\n", module->discourse_coherence);
        seq_printf(m, "    Active: %s\n", module->module_active ? "Yes" : "No");
        seq_printf(m, "\n");
    }
    
    seq_printf(m, "BMD Transfer Statistics:\n");
    seq_printf(m, "  Total BMD Transfers: %llu\n", ctx_copy.total_bmd_transfers);
    seq_printf(m, "  Successful BMD Transfers: %llu\n", ctx_copy.successful_bmd_transfers);
    seq_printf(m, "  Language S-Optimizations: %llu\n", ctx_copy.language_s_optimizations);
    seq_printf(m, "  Processing Cycles: %llu\n", processing_cycles);
    
    if (ctx_copy.total_bmd_transfers > 0) {
        u64 transfer_success_rate = (ctx_copy.successful_bmd_transfers * 100) / ctx_copy.total_bmd_transfers;
        seq_printf(m, "  Transfer Success Rate: %llu%%\n", transfer_success_rate);
    }
    
    seq_printf(m, "\nDiscourse Trajectory Analysis:\n");
    seq_printf(m, "  Analysis Enabled: %s\n", ctx_copy.discourse_analysis_enabled ? "Yes" : "No");
    seq_printf(m, "  Trajectory Length: %u\n", ctx_copy.current_trajectory.trajectory_length);
    seq_printf(m, "  Overall Coherence: %u/1000\n", ctx_copy.current_trajectory.overall_coherence);
    seq_printf(m, "  Semantic Connectivity: %u\n", ctx_copy.current_trajectory.semantic_connectivity);
    seq_printf(m, "  Disorder Measure: %u/1000\n", ctx_copy.current_trajectory.disorder_measure);
    seq_printf(m, "  Hyperconnection Detected: %s\n", 
               ctx_copy.current_trajectory.hyperconnection_detected ? "Yes" : "No");
    
    return 0;
}

static int language_bmd_proc_open(struct inode *inode, struct file *file)
{
    return single_open(file, language_bmd_proc_show, NULL);
}

static const struct proc_ops language_bmd_proc_ops = {
    .proc_open = language_bmd_proc_open,
    .proc_read = seq_read,
    .proc_lseek = seq_lseek,
    .proc_release = single_release,
};

/*
 * Public API functions for other kernel modules
 */

// Add a new language processing module
int language_bmd_add_module(const char *name)
{
    unsigned long flags;
    int ret;
    
    if (!name || lang_bmd_ctx.active_module_count >= MAX_LANGUAGE_MODULES)
        return -EINVAL;
    
    spin_lock_irqsave(&lang_bmd_ctx.context_lock, flags);
    
    ret = initialize_language_module(&lang_bmd_ctx.modules[lang_bmd_ctx.active_module_count],
                                    lang_bmd_ctx.active_module_count,
                                    name);
    
    if (ret == 0) {
        lang_bmd_ctx.active_module_count++;
    }
    
    spin_unlock_irqrestore(&lang_bmd_ctx.context_lock, flags);
    
    return ret;
}
EXPORT_SYMBOL(language_bmd_add_module);

// Enable/disable discourse analysis
int language_bmd_set_discourse_analysis(bool enabled)
{
    unsigned long flags;
    
    spin_lock_irqsave(&lang_bmd_ctx.context_lock, flags);
    lang_bmd_ctx.discourse_analysis_enabled = enabled;
    spin_unlock_irqrestore(&lang_bmd_ctx.context_lock, flags);
    
    return 0;
}
EXPORT_SYMBOL(language_bmd_set_discourse_analysis);

/*
 * Module initialization and cleanup
 */
static int __init language_bmd_init(void)
{
    int ret;
    
    printk(KERN_INFO "Language BMD: Initializing language BMD processing system\n");
    
    // Initialize language BMD context
    memset(&lang_bmd_ctx, 0, sizeof(lang_bmd_ctx));
    spin_lock_init(&lang_bmd_ctx.context_lock);
    spin_lock_init(&lang_bmd_ctx.current_trajectory.trajectory_lock);
    atomic64_set(&lang_bmd_ctx.processing_cycles, 0);
    
    // Create language processing workqueue
    lang_bmd_ctx.language_wq = create_singlethread_workqueue("language_bmd_processing");
    if (!lang_bmd_ctx.language_wq) {
        printk(KERN_ERR "Language BMD: Failed to create language processing workqueue\n");
        return -ENOMEM;
    }
    
    // Initialize language processing work
    INIT_DELAYED_WORK(&lang_bmd_ctx.language_work, language_bmd_worker);
    
    // Create proc entry
    if (!proc_create("language_bmd", 0444, NULL, &language_bmd_proc_ops)) {
        printk(KERN_ERR "Language BMD: Failed to create proc entry\n");
        destroy_workqueue(lang_bmd_ctx.language_wq);
        return -ENOMEM;
    }
    
    // Initialize default language modules
    ret = language_bmd_add_module("lexical");
    if (ret) goto cleanup;
    
    ret = language_bmd_add_module("syntactic");
    if (ret) goto cleanup;
    
    ret = language_bmd_add_module("semantic");
    if (ret) goto cleanup;
    
    ret = language_bmd_add_module("pragmatic");
    if (ret) goto cleanup;
    
    // Enable discourse analysis by default
    lang_bmd_ctx.discourse_analysis_enabled = true;
    
    // Start language processing system
    lang_bmd_ctx.active = true;
    queue_delayed_work(lang_bmd_ctx.language_wq, &lang_bmd_ctx.language_work, 0);
    
    printk(KERN_INFO "Language BMD: Successfully initialized\n");
    printk(KERN_INFO "Language BMD: Processing interval: %u microseconds\n", 
           LANG_PROCESSING_INTERVAL);
    printk(KERN_INFO "Language BMD: Matrix associative memory language processing active\n");
    
    return 0;

cleanup:
    // Cleanup on error
    for (int i = 0; i < lang_bmd_ctx.active_module_count; i++) {
        cleanup_language_module(&lang_bmd_ctx.modules[i]);
    }
    destroy_workqueue(lang_bmd_ctx.language_wq);
    return ret;
}

static void __exit language_bmd_exit(void)
{
    int i;
    
    printk(KERN_INFO "Language BMD: Shutting down language BMD processing system\n");
    
    // Stop language processing system
    lang_bmd_ctx.active = false;
    cancel_delayed_work_sync(&lang_bmd_ctx.language_work);
    
    // Cleanup language modules
    for (i = 0; i < lang_bmd_ctx.active_module_count; i++) {
        cleanup_language_module(&lang_bmd_ctx.modules[i]);
    }
    
    // Cleanup workqueue
    destroy_workqueue(lang_bmd_ctx.language_wq);
    
    // Remove proc entry
    remove_proc_entry("language_bmd", NULL);
    
    printk(KERN_INFO "Language BMD: Successfully shutdown\n");
}

module_init(language_bmd_init);
module_exit(language_bmd_exit); 